{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "A popular way of tuning the model's hyper-parameters is to conduct a grid search. It simply means to choose a several sets of hyper-parameters combinations, train the model using each combination, and finally comparing the performance of each one of the trained models.\n",
    "\n",
    "In this notebook we will review the basic concepts you need to know in order to successfully tune your model using ```GridSearchCV``` from **Sklearn**.\n",
    "\n",
    "We will use a xgboost classifier to demonstrate how to conduct a grid search. However, the technique can be use with any other model. We will start by importing the classifier, the grid search function, and the function that creates the data (dummy data) we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Import grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Import functions to create dummy data\n",
    "from mlb_misc_functions import obtain_train_clf_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Creation\n",
    "We will start by creating the data we will be using in this notebook. We will create two lists (**train_x** and **train_y**) representing the features and the targets already in the format needed for training. In the following block of code these lists are created using the function ```obtain_train_clf_data()```. After that, we print the first 3 elements of each list and the number of elements in each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first 3 elements of train_x:\n",
      "[[-10   1   6  -3  -1]\n",
      " [  0  -2  -1 -10   2]\n",
      " [ -9   1  -4 -10   2]]\n",
      "the first 3 elements of train_y:\n",
      "[0 0 0]\n",
      "number of elements in the lists\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "#Create the lists\n",
    "train_x, train_y = obtain_train_clf_data()\n",
    "\n",
    "#Print the first 3 elements of each list, and the number of elements in the lists\n",
    "print(\"the first 3 elements of train_x:\")\n",
    "print(train_x[:3])\n",
    "print(\"the first 3 elements of train_y:\")\n",
    "print(train_y[:3])\n",
    "print(\"number of elements in the lists\")\n",
    "print(len(train_x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each list contains 8,000 elements. In the case of **train_x** each element is a list containing 5 numbers, these are the model’s features. On the other hand, the list **train_y** only contains numbers (0 or 1), these are model’s targets\n",
    "\n",
    "# Grid Search Implementation\n",
    "The first step is to create the classifier, in this case Xgboost. After than, we define the hyper-parameter space we are going to explore. See the block of code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create classifier\n",
    "xgb_clf = XGBClassifier()\n",
    "\n",
    "#Define hyper-parameter space\n",
    "parameters = {\"n_estimators\": [50, 70, 100], \n",
    "              \"max_depth\": [2, 4, 6],\n",
    "             }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the hyper-parameter space is defined using a dictionary. In our case we will only go over 3 values for **n_estimators** and 3 values for **max_depth**, for a total of 9 possible combinations.\n",
    "\n",
    "The next step is to create our grid search object. This is done by passing the classifier, the dictionary with the hyper parameter space, a method to evaluate the predictions on the test set, and the cross validation splitting strategy to the ```GridSearchCV()``` function. After the object is created, we use the ```fit()``` method to launch our grid search.\n",
    "\n",
    "Before we move on, it is important to mention that we will use the f1 score to evaluate the performance of the classifier. You can use other scoring methods. See [here](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   18.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [50, 70, 100], 'max_depth': [2, 4, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create grid search object\n",
    "grid_search = GridSearchCV(xgb_clf, parameters, scoring='f1', cv=5, verbose=1)\n",
    "\n",
    "#launch the grid search\n",
    "grid_search.fit(train_x, train_y, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to mention that we are using a cross validation of 5 folds (cv=5) with a 3x3 hyper-parameter grid. This means that we are doing the following:\n",
    "* Split the data in 5 sets (cv=5), lets call them A, B, C, D, E\n",
    "* Pick one combination of hyper-parameters (9 possible combinations)\n",
    "* Train the classifier using 4 of the sets (let's say A, B, C, D) and obtain scores on the last set (in this case E)\n",
    "* Repeat the last two steps for all possible combinations (9 hyper-parameters, and 5 cv groups)\n",
    "\n",
    "# Results\n",
    "\n",
    "Now we can obtain the best hyper-parameter combination, and the score using ```best_params_``` and ```best_score_```, see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'n_estimators': 100}\n",
      "0.8890910000329503\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final words\n",
    "We went over the basic concepts behind **grid search**, by now you should be able to use **GridSearchCV** to tune up the hyper-parameters of your model. It is now your time to start coding! try the following:\n",
    "* Add other hyper-parameters to the dicctionary.\n",
    "* Try a different value for your cross validation splitting strategy (cv = 3, or 6).\n",
    "* Use a different classifier.\n",
    "* Use a different scoring method to meassure the performance of your classifiers.\n",
    "* Try setting verbose=2 when you create the grid search object.\n",
    "\n",
    "More information about the arguments passed to ```GridSearchCV()``` can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
