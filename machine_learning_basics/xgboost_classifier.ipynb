{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost Classifier\n",
    "This notebook reviews the basic concepts you need to know in order to\n",
    "sucessfully create a **Xgboost** classifier. We will be using **XGBClassifier** from **xgboost**. If you do not have it installed, run the following line in your terminal:\n",
    "\n",
    "> conda install -c anaconda py-xgboost\n",
    "\n",
    "In the following block of code we load the functions we will be using through this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Import functions to create and split the data\n",
    "from mlb_misc_functions import create_clf_table_1, prep_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load and Prep\n",
    "\n",
    "In the following block of code we will create a modeling table (**model_data**) using the ```create_clf_table_1``` function. This is a dummy/fake table that resembles the format of real data. The table has 7 columns. One of the columns is a row unique identifier, the following 5 columns are features, while the last column is the target. In this case the target takes the values 0 and 1. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-8</td>\n",
       "      <td>-7</td>\n",
       "      <td>3</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-7</td>\n",
       "      <td>-6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  feature_1  feature_2  feature_3  feature_4  feature_5  target\n",
       "0       0         -7         -1         -9         -8          8       0\n",
       "1       1          4         -2          2         -6          4       1\n",
       "2       2          0          5          0         -6          3       1\n",
       "3       3          4         -8         -7          3         -9       0\n",
       "4       4         -7         -6          2          7         -4       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the funciton that creates the table. 10,000 rows\n",
    "model_data = create_clf_table_1(10000)\n",
    "\n",
    "#print the first 5 rows to screen\n",
    "model_data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to split the data into training and a testing set, and put it in a format that our classifier can read it. In the block of code below we do that using a wrapper function called ```prep_model_data```. This function takes in the a pandas table, and two lists: one with the name of the column used as target, and a second one with the name of the features. **Note** that this function (```prep_model_data```) is a custom wrapper function that we are importing from the file **mlb_misc_functions**. We will talk about how to split a training set into training and testing sets in another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target and features names\n",
    "target = [\"target\"]\n",
    "features = [\"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\", \"feature_5\"]\n",
    "\n",
    "#Prep the data for training\n",
    "train_x, train_y, test_x, test_y = prep_model_data(model_data, target, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, letâ€™s take a look at the first 5 elements of **train_x** and **train_y**. **train_x** is a list of lists where each element (a list) contains the feature values. On the other hand, **train_y** is a simple list containing the targets (0 or 1). See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6  -2  -7   8   1]\n",
      " [ -4   2   6   5  -3]\n",
      " [-10   7   1   6   1]\n",
      " [  7   8 -10  -3   7]\n",
      " [  3  -1   4   8  -7]]\n",
      "[1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Print 5 first elements\n",
    "print(train_x[:5])\n",
    "print(train_y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training\n",
    "\n",
    "Now we will create our classifier and train it on the training data (**train_x** and **train_y**), se below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create classifier\n",
    "xgb_clf = XGBClassifier(n_estimators=100)\n",
    "\n",
    "#Train the classifier\n",
    "xgb_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to notice that we are initializing our Xgboost classifier with ```n_estimators=100```, while using the default value for all the other hyperparameters, we will talk about how to tune hyperparamters in a different notebook. For now, you can read about all the other hyperparameters [here](https://xgboost.readthedocs.io/en/latest/python/python_api.html).\n",
    "\n",
    "## Predictions and Probabilities\n",
    "\n",
    "Once you have your Xgboost classifier trained, you can give it new data and either obtain predictions on the target (0s or 1s) or probabilities (numbers between 0 and 1).\n",
    "\n",
    "The probabilities are obtained using the method ```predict_proba```, while the predictions are obtained using the method ```predict```. In the following block of code we obtain the predictions and probabilities for the testing set, and we print to screen the first 5 elements of each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb_clf.predict(test_x)\n",
    "probabilities = xgb_clf.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.53015244 0.46984753]\n",
      " [0.40298903 0.59701097]\n",
      " [0.9807196  0.01928039]\n",
      " [0.97738254 0.02261743]\n",
      " [0.56789935 0.43210062]]\n"
     ]
    }
   ],
   "source": [
    "print(probabilities[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the list ```predictions``` is a simple array where each element takes the values 0 or 1, the list ```probabilities``` is an array where each element is also an array containing 2 elements. The first element is the probability of belonging to class 0, and the second element is the probability of belonging to the class 1. The addition of both numbers is always 1.\n",
    "\n",
    "It is important to mention that the probabilities have more information than the predictions, actually the predictions can be constructed using the probabilities. In order to do so, you only need to choose a threshold, if the probability for class 1 is larger than the chosen threshold, then the prediction would be 1, otherwise it would be 0.\n",
    "\n",
    "## Final words\n",
    "We have covered the basic concepts to create and train a Xgboost classifier, plus how to obtain predictions and probabilities. Now is your turn to start coding! Try to use some metric (such as precision and recall) to evaluate the performance of your model, and try to specify other hyper parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
